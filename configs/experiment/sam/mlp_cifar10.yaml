# @package _global_

# to execute this experiment run:
# python run.py experiment=fixmatch_cifar10
defaults:
  - override /trainer: minimal.yaml # choose trainer from 'configs/trainer/'
  - override /data: cifar10.yaml
  - override /callbacks: default.yaml
  - override /logger: many_loggers.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

seed: 12345
resume: null

trainer:
  min_epochs: 1
  max_steps: 78000
  max_epochs: ${trainer.max_steps}
  benchmark: true

data:
  train:
    loader:
      batch_size: 128
  val:
    loader:
      batch_size: 512

task:
  _target_: src.tasks.supervised.ClassificationTask
  model:
    _target_: timm.models.mlp_mixer.MlpMixer
    num_classes: 10
    img_size: 32
    in_chans: 3
    patch_size: 4
    num_blocks: 12
    embed_dim: 256
    drop_rate: 0.
    drop_path_rate: 0.
    nlhb: false
    stem_norm: false
  optimizer:
    _target_: src.optim.OptimRegime
    regime:
      - epoch: 0
        optimizer: SGD
        lr: 0.1
        momentum: 0.9
        regularizer:
          name: "WeightDecay"
          value: 5e-4
        lr_scheduler:
          name: CosineAnnealingLR
          time_frame: step
          T_max: ${trainer.max_steps}
          eta_min: 0